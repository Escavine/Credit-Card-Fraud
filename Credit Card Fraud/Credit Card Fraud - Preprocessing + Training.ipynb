{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c508da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pre-requisite libraries\n",
    "import numpy as np # For mathematical calculations\n",
    "import pandas as pd # For dealing with dataframes (i.e. pd.read_csv())\n",
    "import time # Measuring start and end training times\n",
    "import matplotlib.pyplot as plt # Displaying graphs \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be26a1",
   "metadata": {},
   "source": [
    "# 1. Comprehending the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3be16",
   "metadata": {},
   "source": [
    "## Opening CSV + Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26dc2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Khalid\\Desktop\\ML Projects\\Beginner\\Credit Card Fraud\\creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f99dd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac8fc28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb06abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400755e1",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef5080",
   "metadata": {},
   "source": [
    "## Scaling + distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8abf7c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can see from the dataset that the V1, V2, V3 values aren't understandable and the only sensible pieces of data are amount and time\n",
    "# Due to this, we can scale these features with robust scaler to mitigate outliers (data that falls out of place)\n",
    "# We will do this by creating new features (feature engineering) called 'scaled_amount' and 'scaled_time'\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler \n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.\n",
    "                                              reshape(-1,1))\n",
    "\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Amount'].values.\n",
    "                                            reshape(-1,1))\n",
    "\n",
    "df.drop(['Time', 'Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866a8e17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>1.783274</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.269825</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>4.983721</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274     1.783274 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.269825  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721     4.983721 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291     1.418291 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579     0.670579 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_amount = df['scaled_amount']\n",
    "scaled_time = df['scaled_time']\n",
    "\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7363037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non frauded cases:  99.83 % of the dataset.\n",
      "Frauded cases:  0.17 % of the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Checking the percentage of frauded and non-frauded cases\n",
    "\n",
    "print(\"Non frauded cases: \", round(df['Class'].value_counts()[0]/len(df) \n",
    "                                   * 100, 2), \"% of the dataset.\")\n",
    "\n",
    "print(\"Frauded cases: \", round(df['Class'].value_counts()[1]/len(df) \n",
    "                                   * 100, 2), \"% of the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41af7bc",
   "metadata": {},
   "source": [
    "## Random Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a305caaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-0.179976</td>\n",
       "      <td>-0.179976</td>\n",
       "      <td>-0.427191</td>\n",
       "      <td>0.745708</td>\n",
       "      <td>1.761811</td>\n",
       "      <td>-0.165130</td>\n",
       "      <td>0.058298</td>\n",
       "      <td>-0.213413</td>\n",
       "      <td>0.647323</td>\n",
       "      <td>0.073464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052828</td>\n",
       "      <td>-0.201681</td>\n",
       "      <td>-0.432070</td>\n",
       "      <td>0.013164</td>\n",
       "      <td>0.161606</td>\n",
       "      <td>-0.401310</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>0.102549</td>\n",
       "      <td>-0.116571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248296</th>\n",
       "      <td>-0.307413</td>\n",
       "      <td>-0.307413</td>\n",
       "      <td>-0.613696</td>\n",
       "      <td>3.698772</td>\n",
       "      <td>-5.534941</td>\n",
       "      <td>5.620486</td>\n",
       "      <td>1.649263</td>\n",
       "      <td>-2.335145</td>\n",
       "      <td>-0.907188</td>\n",
       "      <td>0.706362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354773</td>\n",
       "      <td>0.319261</td>\n",
       "      <td>-0.471379</td>\n",
       "      <td>-0.075890</td>\n",
       "      <td>-0.667909</td>\n",
       "      <td>-0.642848</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.488410</td>\n",
       "      <td>0.292345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-0.027947</td>\n",
       "      <td>-0.027947</td>\n",
       "      <td>1.171439</td>\n",
       "      <td>0.474974</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>1.264303</td>\n",
       "      <td>0.116234</td>\n",
       "      <td>-0.865986</td>\n",
       "      <td>0.554393</td>\n",
       "      <td>-0.276375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119439</td>\n",
       "      <td>0.070051</td>\n",
       "      <td>0.278843</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>0.426278</td>\n",
       "      <td>0.744938</td>\n",
       "      <td>-0.274728</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239501</th>\n",
       "      <td>3.007895</td>\n",
       "      <td>3.007895</td>\n",
       "      <td>-6.682832</td>\n",
       "      <td>-2.714268</td>\n",
       "      <td>-5.774530</td>\n",
       "      <td>1.449792</td>\n",
       "      <td>-0.661836</td>\n",
       "      <td>-1.148650</td>\n",
       "      <td>0.849686</td>\n",
       "      <td>0.433427</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.928527</td>\n",
       "      <td>0.220526</td>\n",
       "      <td>1.187013</td>\n",
       "      <td>0.335821</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.803110</td>\n",
       "      <td>0.044033</td>\n",
       "      <td>-0.054988</td>\n",
       "      <td>0.082337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143336</th>\n",
       "      <td>3.226717</td>\n",
       "      <td>3.226717</td>\n",
       "      <td>-6.713407</td>\n",
       "      <td>3.921104</td>\n",
       "      <td>-9.746678</td>\n",
       "      <td>5.148263</td>\n",
       "      <td>-5.151563</td>\n",
       "      <td>-2.099389</td>\n",
       "      <td>-5.937767</td>\n",
       "      <td>3.578780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135711</td>\n",
       "      <td>0.954272</td>\n",
       "      <td>-0.451086</td>\n",
       "      <td>0.127214</td>\n",
       "      <td>-0.339450</td>\n",
       "      <td>0.394096</td>\n",
       "      <td>1.075295</td>\n",
       "      <td>1.649906</td>\n",
       "      <td>-0.394905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "121         -0.179976    -0.179976 -0.427191  0.745708  1.761811 -0.165130   \n",
       "248296      -0.307413    -0.307413 -0.613696  3.698772 -5.534941  5.620486   \n",
       "239         -0.027947    -0.027947  1.171439  0.474974  0.011761  1.264303   \n",
       "239501       3.007895     3.007895 -6.682832 -2.714268 -5.774530  1.449792   \n",
       "143336       3.226717     3.226717 -6.713407  3.921104 -9.746678  5.148263   \n",
       "\n",
       "              V5        V6        V7        V8  ...       V20       V21  \\\n",
       "121     0.058298 -0.213413  0.647323  0.073464  ...  0.052828 -0.201681   \n",
       "248296  1.649263 -2.335145 -0.907188  0.706362  ...  0.354773  0.319261   \n",
       "239     0.116234 -0.865986  0.554393 -0.276375  ... -0.119439  0.070051   \n",
       "239501 -0.661836 -1.148650  0.849686  0.433427  ... -1.928527  0.220526   \n",
       "143336 -5.151563 -2.099389 -5.937767  3.578780  ...  0.135711  0.954272   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "121    -0.432070  0.013164  0.161606 -0.401310  0.047423  0.102549 -0.116571   \n",
       "248296 -0.471379 -0.075890 -0.667909 -0.642848  0.070600  0.488410  0.292345   \n",
       "239     0.278843 -0.097491  0.426278  0.744938 -0.274728  0.008472  0.015492   \n",
       "239501  1.187013  0.335821  0.215683  0.803110  0.044033 -0.054988  0.082337   \n",
       "143336 -0.451086  0.127214 -0.339450  0.394096  1.075295  1.649906 -0.394905   \n",
       "\n",
       "        Class  \n",
       "121         0  \n",
       "248296      1  \n",
       "239         0  \n",
       "239501      1  \n",
       "143336      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New dataframes for frauded and non-frauded transactions\n",
    "# We are already aware that there's 492 frauded transactions\n",
    "# Therefore, we've limited the non frauded transactions to 492 to prevent overfitting\n",
    "\n",
    "# Due to the reduced dataframe size, there is a risk of inaccuracy\n",
    "\n",
    "frauded_df = df.loc[df['Class'] == 1]\n",
    "non_frauded_df = df.loc[df['Class'] == 0][:492]\n",
    "\n",
    "balanced_df = pd.concat([frauded_df, non_frauded_df]) # Joining the two dataframes together\n",
    "\n",
    "# Sampling the dataset\n",
    "new_df = balanced_df.sample(frac=1, random_state=42)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ade99994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non frauded cases:  50.0 % of the dataset.\n",
      "Frauded cases:  50.0 % of the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Now the number of frauded and non-frauded cases are even\n",
    "# Though there's a risk of accuracy loss due to dataframe being diluted\n",
    "# 200,000+ --> 984\n",
    "\n",
    "print(\"Non frauded cases: \", round(new_df['Class'].value_counts()[0]/len(new_df) \n",
    "                                   * 100, 2), \"% of the dataset.\")\n",
    "\n",
    "print(\"Frauded cases: \", round(new_df['Class'].value_counts()[1]/len(new_df) \n",
    "                                   * 100, 2), \"% of the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f86e93",
   "metadata": {},
   "source": [
    "### We can now see that the dataset is now equal, though there is a huge loss in data which can affect accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925aa7a5",
   "metadata": {},
   "source": [
    "## Checking the distribution of data in the new dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62017b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # Dimensonality reduction\n",
    "from sklearn.manifold import TSNE # Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf98a445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For this instance, we will use T-SNE to reduce the dimensonality of the data and find the distributions in the datapoints\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d5ee1",
   "metadata": {},
   "source": [
    "## Oversampling (SMOTE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a960947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE # Handling imbalanced data within the dataset\n",
    "\n",
    "# oversample = SMOTE(random_state=42) # Defining SMOTE\n",
    "\n",
    "# X, y = oversample.fit_resample(X, y) # Resampling the data with synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9433bcd",
   "metadata": {},
   "source": [
    "# 3. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb15f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve # For overfitting detection\n",
    "from sklearn.model_selection import cross_val_score # For overfitting detection\n",
    "from sklearn.ensemble import RandomForestRegressor # Will be used for the model\n",
    "from xgboost import XGBRegressor # Alternative model\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report # For confusion metrics as we are dealing with binary classification ('1' and '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afaa925",
   "metadata": {},
   "source": [
    "### Training (Random Undersampling Approach) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2282480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Seperating the training and testing process\n",
    "\n",
    "y = new_df['Class'] # Target predictor to determine frauded transactions\n",
    "\n",
    "X = new_df.drop(columns=['Class']) # Dropping the target predictor column\n",
    "\n",
    "# Test-train split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2,\n",
    "                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4712d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model, since it involves binary classes (i.e 1 for fraud and 0 for non fraud)\n",
    "# We will use a regression model (i.e. random forest regressor)\n",
    "\n",
    "# We have slightly modified the model to use all CPU cores for performance sake\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=1,\n",
    "                             max_depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90359953",
   "metadata": {},
   "source": [
    "### K-fold cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb2d552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.026473\n",
      "\n",
      "Model Performance: [-0.08030686 -0.08345263 -0.07875817 -0.08684584 -0.10807667]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# We will use cross-validation to determine which model is the most efficient when the training and valdation data are split\n",
    "\n",
    "scores = cross_val_score(model, X, y,\n",
    "                          n_jobs=-1,\n",
    "                         cv=5, scoring=\n",
    "                         'neg_mean_absolute_error')\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "cross_val_seconds = end_time - start_time # Find the difference\n",
    "cross_val_minutes = cross_val_seconds / 60 # Convert to minutes format\n",
    "\n",
    "print(f\"Training time: {cross_val_minutes:2f}\")\n",
    "print(f\"\\nModel Performance: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac3e22",
   "metadata": {},
   "source": [
    "### Confusion Matrix + F-1 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73334064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b4c58fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_valid, y_pred)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(conf_matrix)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[0;32m    233\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    234\u001b[0m ):\n\u001b[0;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
